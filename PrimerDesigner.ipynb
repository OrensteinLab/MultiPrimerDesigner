{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OrensteinLab/PrimerDesigner/blob/main/Tracking_Timings_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-cQNE8To4yW"
      },
      "source": [
        "#Pre-Calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFTaJFH_qB2p"
      },
      "source": [
        "##Installs & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5Qvu79FpBUL",
        "outputId": "fed7ea03-6783-4245-a004-924b35b4bedb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (3.3.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh) (1.23.5)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh) (23.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh) (6.3.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh) (2023.10.1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh) (2.1.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting seequence\n",
            "  Cloning https://github.com/FordyceLab/seequence.git to /tmp/pip-install-45mdyy6q/seequence_ddc69c614d1e40fdb5bc4b5df4a57c11\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/FordyceLab/seequence.git /tmp/pip-install-45mdyy6q/seequence_ddc69c614d1e40fdb5bc4b5df4a57c11\n"
          ]
        }
      ],
      "source": [
        "!pip install -U bokeh seaborn pandas\n",
        "!pip install git+https://github.com/FordyceLab/seequence.git#egg=seequence\n",
        "!pip install primer3-py biopython pandarallel\n",
        "!pip install pulp\n",
        "!pip install gurobipy\n",
        "!pip install biopython==1.75\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu59O-XqpDCW"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import time\n",
        "\n",
        "import random as rand\n",
        "from itertools import product\n",
        "\n",
        "from seequence.view import *\n",
        "from seequence.color import *\n",
        "\n",
        "from pandarallel import pandarallel as pl\n",
        "pl.initialize()\n",
        "\n",
        "import primer3 as p3\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqUtils import GC, seq1, seq3\n",
        "from Bio.SeqUtils.CodonUsage import SharpEcoliIndex, SynonymousCodons\n",
        "\n",
        "import itertools as it\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.precision', 1)\n",
        "import networkx as nx\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from bokeh.models.annotations import Span\n",
        "from bokeh.models import Select\n",
        "from bokeh.layouts import column\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "import gurobipy as gp\n",
        "\n",
        "import pickle\n",
        "\n",
        "import tracemalloc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def revcomp(seq):\n",
        "  return str(Seq(seq).reverse_complement())\n",
        "def translate(seq):\n",
        "  return str(Seq(seq).translate())\n",
        "\n",
        "# clear_output()\n",
        "print('Ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXfAgj6lqJQn"
      },
      "source": [
        "##Codon Table + Important Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJX5GMTapFsq"
      },
      "outputs": [],
      "source": [
        "lst = []\n",
        "for k,v in SynonymousCodons.items():\n",
        "  if k!='STOP':\n",
        "    for vv in v:\n",
        "      lst.append((seq1(k), k, vv, SharpEcoliIndex[vv]))\n",
        "codon_df = pd.DataFrame(lst, columns=['c1','c3','codon','freq']).sort_values(['c1','freq'], ascending=[True,False])\n",
        "codon_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KQla4gkp0QF"
      },
      "outputs": [],
      "source": [
        "def create_mut_df():\n",
        "  mut_df = pd.DataFrame(columns=['lib_i','wt_aa','pos_aa','mut_aa']) #library #, wildtype, position, mutation\n",
        "  mut_df.pos_aa = mut_df.pos_aa.astype(int)\n",
        "\n",
        "  # GENERATE (V scan):\n",
        "  scan = pd.DataFrame()\n",
        "  scan['wt_aa'] = list(mutreg_aa)\n",
        "  scan['pos_aa'] = list(range(len(mutreg_aa)))\n",
        "  scan['mut_aa'] = ['V' if aa!='V' else 'A' for aa in mutreg_aa] #V: A, Else: V\n",
        "  scan['lib_i'] = 0\n",
        "  mut_df = pd.concat([mut_df, scan])\n",
        "\n",
        "  # GENERATE (P scan):\n",
        "  scan = pd.DataFrame()\n",
        "  scan['wt_aa'] = list(mutreg_aa)\n",
        "  scan['pos_aa'] = list(range(len(mutreg_aa)))\n",
        "  scan['mut_aa'] = ['P' if aa!='P' else 'A' for aa in mutreg_aa]#P: A, Else: P\n",
        "  scan['lib_i'] = 0\n",
        "  #mut_df = mut_df.append(scan)\n",
        "  mut_df = pd.concat([mut_df, scan])\n",
        "\n",
        "  # GENERATE (G scan):\n",
        "  scan = pd.DataFrame()\n",
        "  scan['wt_aa'] = list(mutreg_aa)\n",
        "  scan['pos_aa'] = list(range(len(mutreg_aa)))\n",
        "  scan['mut_aa'] = ['G' if aa!='G' else 'A' for aa in mutreg_aa]#G: A, Else: G\n",
        "  scan['lib_i'] = 1\n",
        "  #mut_df = mut_df.append(scan)\n",
        "  mut_df = pd.concat([mut_df, scan])\n",
        "\n",
        "  # v DO NOT EDIT v --------------------------------------------------------------\n",
        "  # nt (codon) info\n",
        "  mut_df['start_nt'] = 3*mut_df.pos_aa\n",
        "  mut_df['stop_nt'] = mut_df.start_nt+3\n",
        "  mut_df['wt_nt'] = mut_df.apply(lambda row: mutreg_nt[row.start_nt:row.stop_nt], axis=1) #finds codon between start & stop for a given row\n",
        "  mut_df['mut_nt'] = codon_df.set_index('c1').query('freq==1.0').loc[mut_df.mut_aa,'codon'].values #finds the codon (with freq 1) that produces the new mutated aa\n",
        "\n",
        "  mut_df = mut_df.sort_values(['lib_i','pos_aa','mut_aa']).reset_index(drop=True)\n",
        "  return mut_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlY4e_TaqpUb"
      },
      "outputs": [],
      "source": [
        "def calcOffTarget(primer, seq, start):\n",
        "  fl,fr = seq[:primer.start-start], seq[primer.stop-start:]\n",
        "  rl,rr = revcomp(fl), revcomp(fr)\n",
        "\n",
        "  res_fl = pcr.calcHeterodimer(primer.seq, fl).todict()\n",
        "  res_fr = pcr.calcHeterodimer(primer.seq, fr).todict()\n",
        "  res_rl = pcr.calcHeterodimer(primer.seq, rl).todict()\n",
        "  res_rr = pcr.calcHeterodimer(primer.seq, rr).todict()\n",
        "\n",
        "  ot_tm = max(res_fl['tm'], res_fr['tm'], res_rl['tm'], res_rr['tm'])\n",
        "  # ot_dg = min(res_fl['dg'], res_fr['dg'], res_rl['dg'], res_rr['dg'])*1e-3\n",
        "  return ot_tm\n",
        "\n",
        "def n_subsequences(sequence, lmin, lmax):\n",
        "  print(sum(len(sequence) - l + 1 for l in range(lmin, lmax+1)))\n",
        "\n",
        "def subsequences(sequence, lmin, lmax): #Generates all subsequences w/ all poss. start-stop pairs\n",
        "  ls = []\n",
        "  for j in range(lmin, lmax+1): #length\n",
        "    for i in range(len(sequence)-j+1): #starting index\n",
        "      start = i\n",
        "      stop = i+j\n",
        "      ls.append([sequence[start:stop], start, stop, stop-start])\n",
        "  return pd.DataFrame(ls, columns=['seq','start','stop','len'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxLGrHMfqu60"
      },
      "outputs": [],
      "source": [
        "def create_primer_df():\n",
        "  # convention: start index of r-primers will be 3' (i.e. start < stop)\n",
        "  primer_f = pd.DataFrame(columns=['seq','start','stop','fr','len'])\n",
        "  primer_f[['seq','start','stop','len']] = subsequences(sequence_nt, primer_lmin, primer_lmax)\n",
        "  primer_f['fr'] = 'f'\n",
        "\n",
        "  #Shifting so that 0 is at the start of mutreg (upstream has negative values)\n",
        "  primer_f['start'] = primer_f.start - mutreg_start\n",
        "  primer_f['stop'] = primer_f.stop - mutreg_start\n",
        "\n",
        "  #Creating reverse primers at same locations\n",
        "  primer_r = primer_f[['seq','start','stop','fr','len']].copy()\n",
        "  primer_r['fr'] = 'r'\n",
        "  primer_r['seq'] = primer_r.seq.apply(revcomp)\n",
        "\n",
        "  #Concatenating Forward & Reverse\n",
        "  primer_df = pd.concat([primer_f,primer_r])\n",
        "  primer_df.sort_values(by=['start','stop','fr'], inplace=True)\n",
        "\n",
        "  #Calculating \"Cost\" Values\n",
        "  primer_df['gc'] = primer_df.seq.apply(GC)\n",
        "  primer_df['tm'] = primer_df.seq.apply(pcr.calcTm)\n",
        "  res = primer_df.seq.parallel_apply(lambda s: pcr.calcHairpin(s).todict())\n",
        "  primer_df['hp_tm'] = res.apply(lambda res: res['tm'])\n",
        "  primer_df['hp_dg'] = res.apply(lambda res: res['dg']*1e-3)\n",
        "  res = primer_df.seq.parallel_apply(lambda s: pcr.calcHomodimer(s).todict())\n",
        "  primer_df['ho_tm'] = res.apply(lambda res: res['tm'])\n",
        "  primer_df['ho_dg'] = res.apply(lambda res: res['dg']*1e-3)\n",
        "\n",
        "  def primer_cost(primer):\n",
        "    # calculates primer cost based on homodimer an haipin delta G, tm cost, and len cost\n",
        "    hp_dg_max = -4\n",
        "    ho_dg_max = -8\n",
        "    tm_min = 58\n",
        "\n",
        "    tm_cost = max(0, tm_min-primer.tm)**1.7\n",
        "    hp_cost = max(0, hp_dg_max - primer.hp_dg)**1.2\n",
        "    ho_cost = max(0, ho_dg_max - primer.ho_dg)**1.2\n",
        "    len_cost = primer.len*1e-5\n",
        "\n",
        "    cost = hp_cost + ho_cost + len_cost + tm_cost\n",
        "    return cost\n",
        "\n",
        "  primer_df['cost'] = primer_df.parallel_apply(primer_cost, axis=1)\n",
        "  primer_df['log10cost'] = primer_df.cost.apply(np.log10)\n",
        "\n",
        "  primer_df.reset_index(inplace=True)\n",
        "  primer_f = primer_df.query('fr==\"f\"').reset_index(drop=True)\n",
        "  primer_r = primer_df.query('fr==\"r\"').reset_index(drop=True)\n",
        "  primer_df.set_index(['start','stop','fr'], inplace=True)\n",
        "\n",
        "  return primer_f, primer_df\n",
        "\n",
        "def check_threshold(tm,gc):\n",
        "  # returns false only if the threshold flag is on and primers did not pass threshold\n",
        "  if not apply_threshold:\n",
        "    return True\n",
        "  else:\n",
        "    if min_gc <= gc <= max_gc and  min_tm <= tm <=max_tm:\n",
        "      return True\n",
        "    else:\n",
        "      return False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9Vws9ri2rd2"
      },
      "outputs": [],
      "source": [
        "class Primer:\n",
        "  def __init__(self,start,stop,is_r=False):\n",
        "    assert start < stop\n",
        "    self.start = start\n",
        "    self.stop = stop\n",
        "    self.is_r = is_r #forward or reverse\n",
        "    self.l = stop-start #length\n",
        "    self.w = primer_df.at[self.tup(),'cost'] #total cost value; the fancy notation is b/c\n",
        "                                             #of the hierarchal lookup system in panda.df\n",
        "\n",
        "  def __str__(self):\n",
        "    return ' '.join(map(str,(self.start, self.stop, self.is_r)))\n",
        "  def __repr__(self):\n",
        "    return f'{(\"r\" if self.is_r else\"f\")}({self.start},{self.stop})'\n",
        "  def tup(self):\n",
        "    return (self.start,self.stop,(\"r\" if self.is_r else\"f\"))\n",
        "\n",
        "\n",
        "def actions(primer): #returning possible counterparts (forward -> reverse; reverse -> forward)\n",
        "                     #i.e. this method gets the \"neighbors\"\n",
        "  if not primer.is_r:  # fwd\n",
        "    for oligo_l, primer_l in it.product(reversed(range(oligo_lmin, oligo_lmax+1)),\n",
        "                                        range(primer_lmin,primer_lmax+1)):\n",
        "\n",
        "      stop = primer.start + oligo_l\n",
        "      start = stop - primer_l\n",
        "\n",
        "      if apply_threshold:\n",
        "        # finds tm of forward and reverse strand\n",
        "        tm_f=primer_df.at[primer.tup(),'tm']\n",
        "        tm_r=primer_df.at[(start,stop,\"r\"),'tm']\n",
        "\n",
        "        # if tm difference is larger then max_difference threshold do not add primer to graph\n",
        "        if abs(tm_f-tm_r)>max_difference:\n",
        "          continue\n",
        "\n",
        "      yield Primer(start, stop, is_r=True)\n",
        "\n",
        "  elif primer.is_r:  # rev\n",
        "    for overlap_l, primer_l in it.product(reversed(range(overlap_lmin, overlap_lmax+1)),\n",
        "                                          range(primer_lmin,primer_lmax+1)):\n",
        "\n",
        "      start = primer.stop - overlap_l\n",
        "      stop = start + primer_l\n",
        "\n",
        "\n",
        "      # filter\n",
        "      no_split = (primer.start - stop) >= primer.start%3\n",
        "      if (stop > primer.start) or (not no_split): ## redundant to check first condition?\n",
        "        continue\n",
        "      yield Primer(start, stop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gal-RcyG2uBH"
      },
      "outputs": [],
      "source": [
        "def dfs(primer): #CREATING the graph\n",
        "\n",
        "  tm=primer_df.at[primer.tup(),'tm']\n",
        "  gc=primer_df.at[primer.tup(),'gc']\n",
        "\n",
        "  if (primer.start >= mutreg_l) and primer.is_r and check_threshold(tm,gc) :  # base case (end)\n",
        "    G.add_edge(primer.tup(),'d', weight=0.) #G is global variable defined in next section\n",
        "    return\n",
        "\n",
        "  for next_primer in actions(primer):\n",
        "\n",
        "    is_new = not G.has_node(next_primer.tup()) # check if primer node exists already\n",
        "\n",
        "    tm=primer_df.at[next_primer.tup(),'tm']\n",
        "    gc=primer_df.at[next_primer.tup(),'gc']\n",
        "\n",
        "    passes_threshold= check_threshold(tm,gc) # check if primer passes threshold\n",
        "\n",
        "    # only add edge if primer passes threshold\n",
        "    if passes_threshold:\n",
        "      G.add_edge(primer.tup(),next_primer.tup(), weight=next_primer.w) #weight is the cost of the new primer\n",
        "    if passes_threshold and is_new:\n",
        "      dfs(next_primer)\n",
        "\n",
        "def paths_ct(G, u, d): #total # of paths between two points\n",
        "    if u == d:\n",
        "        return 1\n",
        "    else:\n",
        "        if not G.nodes[u]: #npaths attribute is the # of paths out of u\n",
        "            G.nodes[u]['npaths'] = sum(paths_ct(G, c, d) for c in G.successors(u))\n",
        "        return G.nodes[u]['npaths']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_greedy(G, primer_f, primer_df):\n",
        "  path_ls = [[]]\n",
        "  G_sub = G.copy()\n",
        "  for i in range(num_proteins):\n",
        "    nodes_to_remove = []\n",
        "    for p,n in it.product(path_ls[-1],G_sub.nodes()):\n",
        "      if n=='s' or n=='d':\n",
        "        continue\n",
        "      pn_intersect = n[1]-p[0] > allowed_overlap and p[1]-n[0] > allowed_overlap and n[2]==p[2]  ## check overlap\n",
        "      if pn_intersect:\n",
        "        nodes_to_remove.append(n)\n",
        "    G_sub.remove_nodes_from(set(nodes_to_remove))\n",
        "    try:\n",
        "      path_ls.append([primer for primer in nx.algorithms.shortest_path(G_sub,'s','d', weight='weight')][1:-1])\n",
        "    except:\n",
        "      print(f'WARNING: No feasible primer sequence for lib_{i}; reduce number of libraries or relax constraints.')\n",
        "\n",
        "  path_ls = path_ls[1:]\n",
        "\n",
        "  # # https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
        "  primer_set = pd.DataFrame()\n",
        "  for i,primer_ls in enumerate(path_ls):\n",
        "    primer_set1 = primer_df.loc[primer_ls].copy().reset_index()\n",
        "    primer_set1['lib_i'] = i\n",
        "    primer_set = pd.concat([primer_set, primer_set1])\n",
        "  primer_set['tile_i'] = primer_set.groupby(['lib_i','fr']).cumcount()\n",
        "  primer_set = primer_set[['lib_i','tile_i']+primer_set.columns[:-2].to_list()]\n",
        "\n",
        "  #print(primer_set.groupby('lib_i').cost.sum())\n",
        "  cost = primer_set.cost.sum()\n",
        "\n",
        "  return path_ls, cost"
      ],
      "metadata": {
        "id": "ceiNxaB-D1z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ah8DwG1FeE6"
      },
      "source": [
        "##ILP Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unOF64OiDddN"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "  params = {\n",
        "  \"WLSACCESSID\":\"ae792a7c-4ef2-4636-82c9-911deefc02f8\",\n",
        "  \"WLSSECRET\":\"2fc63fa9-25c7-4eea-a430-2ac9c3940dc6\",\n",
        "  \"LICENSEID\":2458238\n",
        "  }\n",
        "  env = gp.Env(params=params)\n",
        "\n",
        "  # Create the model within the Gurobi environment\n",
        "  model = gp.Model('min-sum', env=env)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjY5w7ZYFgV9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_info(graphs):\n",
        "  setup_start = time.time()\n",
        "  tracemalloc.start()\n",
        "  #Create Model\n",
        "  model = get_model()\n",
        "  #Getting Nodes/Edges\n",
        "  graph_edges = G.edges(data=True)\n",
        "  graph_nodes = [node for node in G.nodes if node != 's' and node != 'd'] #removing s & d nodes\n",
        "\n",
        "  #for G in graphs:\n",
        "   # graphs_edges.append(G.edges(data=True))\n",
        "    #graphs_nodes.append(sorted((node for node in G.nodes if node != 's' and node != 'd'), key = lambda x:x[0:2])) #removing s & d\n",
        "\n",
        "  def create_bins(): # bins take the form (start, end, [])\n",
        "    all_bins = {(start, start+len, c):[] for start in range(*nt_range) for len in range(*l_range) for c in ('f', 'r')}\n",
        "\n",
        "    for node in graph_nodes: #for each node, add it into all the necessary bins\n",
        "      for bin_start in range(node[0], node[1]):\n",
        "        for bin_length in range(*l_range):\n",
        "          if bin_start + bin_length > node[1]:\n",
        "            break\n",
        "          else:\n",
        "            all_bins[(bin_start, bin_start + bin_length, node[2])].append(node)\n",
        "\n",
        "    all_bins = {key:val for key,val in all_bins.items() if val} #no empty bins\n",
        "    return all_bins\n",
        "\n",
        "\n",
        "  all_bins = create_bins()\n",
        "  print(\"Number of Constraints:\", len(all_bins))\n",
        "  print(\"Average Vars Per Constraint\", 1/len(all_bins) * sum(len(val) for _, val in all_bins.items()))\n",
        "\n",
        "\n",
        "  #Converting Graphs to Lists\n",
        "  ij = gp.tuplelist()\n",
        "  w_ij = gp.tupledict()\n",
        "\n",
        "  for edge in graph_edges:\n",
        "    l = (str(edge[0]), str(edge[1])) #i, j\n",
        "    ij.append(l)\n",
        "    w_ij[l] = edge[-1]['weight']\n",
        "\n",
        "  print(\"Finished Conversion\")\n",
        "\n",
        "  #Adding Variables\n",
        "  x = model.addVars(ij, obj=w_ij, vtype=gp.GRB.BINARY)\n",
        "  print(\"Finished Variable Creations\")\n",
        "\n",
        "  # Intersection Constraints\n",
        "  for cnt, nodes in enumerate(all_bins.values()):\n",
        "    all_edges = []\n",
        "    if cnt % (len(all_bins)//25) == 0:\n",
        "          print(int(cnt / len(all_bins) * 100))\n",
        "    for node in nodes:\n",
        "      all_edges.append(x.sum(str(node), '*'))\n",
        "    model.addConstr(gp.quicksum(all_edges) <= 1)\n",
        "  print(\"Finished Intersection constraints!\")\n",
        "\n",
        "\n",
        "  #Single Path Constraints\n",
        "  for n in graph_nodes + ['s', 'd']: #adding s & d back just here\n",
        "    v = str(n)\n",
        "    model.addConstr(sum(x[i,j] for i,j in ij.select(v, '*')) - sum(x[j,i] for j,i in ij.select('*', v)) == (num_proteins if v=='s' else -1 * num_proteins if v=='d' else 0), v)\n",
        "\n",
        "  setup_time = time.time() - setup_start\n",
        "  setup_memory = tracemalloc.get_traced_memory()[1] / 10**6\n",
        "  tracemalloc.stop()\n",
        "\n",
        "  tracemalloc.start()\n",
        "  start_time = time.time()\n",
        "  model.optimize()\n",
        "  ILP_time = time.time() - start_time\n",
        "  ILP_memory = tracemalloc.get_traced_memory()[1] / 10**6\n",
        "  tracemalloc.stop()\n",
        "\n",
        "  def post_processing(variables):\n",
        "    all_proteins = [['s'] for _ in range(num_proteins)]\n",
        "    true_edges = [index for index, var in x.items() if var.X != 0]\n",
        "\n",
        "    while true_edges:\n",
        "      edge = true_edges.pop(0)\n",
        "      added_edge = False\n",
        "      for protein_list in all_proteins:\n",
        "        if edge[0] == protein_list[-1]:\n",
        "          protein_list.append(edge[1])\n",
        "          added_edge = True\n",
        "          break\n",
        "      if not added_edge:\n",
        "        true_edges.append(edge)\n",
        "\n",
        "    return all_proteins\n",
        "\n",
        "  actual_values = post_processing(x)\n",
        "  for cnt, vals in enumerate(actual_values):\n",
        "    print(f\"Protein #{cnt+1} ({len(vals)})\")\n",
        "    print(vals)\n",
        "    print()\n",
        "\n",
        "  return model.numVars, model.numConstrs, setup_time, setup_memory, ILP_time, ILP_memory, actual_values, model.objVal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzIt-1aCqUAH"
      },
      "source": [
        "##Full Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfCGd8GAqMDQ"
      },
      "outputs": [],
      "source": [
        "# human PGT - original\n",
        "upstream_nt = 'ATTTGAATGTATTTAGAAAAATAAACAAATAGGGGTTCCGCGCACATTTCCCCGAAAAGTGCTAGTGGTGCTAGCCCCGCGAAATTAATACGACTCACTATAGGGTCTAGAAATAATTTTGTTTAACTTTAAGAAGGAGATATACATATG'\n",
        "mutreg_nt_full = 'CAAAGCCCAGCACCTGCCGCAGCGCCTGCCCCTGCGGCACGTTCCATCGCAGCTACGCCTCCTAAACTGATCGTGGCAATTAGCGTGGACCAGTTTAGTGCAGACTTGTTCTCGGAGTATCGTCAATATTACACCGGAGGTTTAAAGCGTCTTACATCCGAAGGAGCTGTGTTCCCACGTGGTTATCAGAGTCATGCGGCAACAGAAACGTGTCCTGGTCACTCAACGATCCTGACAGGATCACGTCCGTCACGTACGGGTATTATCGCTAATAACTGGTTCGACTTGGACGCAAAGCGTGAGGATAAAAATCTGTACTGTGCTGAGGATGAATCCCAACCCGGTAGTTCGTCTGACAAGTACGAAGCTTCGCCACTGCACTTAAAGGTACCCACCCTGGGGGGACGCATGAAAGCCGCCAATCCTGCGACTCGTGTCGTCTCTGTTGCCGGCAAGGATCGCGCGGCCATTATGATGGGTGGCGCCACAGCGGATCAGGTCTGGTGGTTAGGGGGGCCTCAGGGGTATGTTTCGTATAAGGGTGTAGCGCCAACTCCCCTTGTAACACAGGTCAATCAGGCCTTTGCACAGCGCTTAGCTCAGCCGAACCCGGGATTTGAGTTGCCTGCTCAGTGCGTCAGCAAGGACTTTCCTGTTCAAGCGGGAAATCGCACAGTGGGTACCGGCCGCTTCGCCCGTGATGCTGGTGACTACAAAGGTTTTCGCATTTCCCCGGAGCAGGATGCTATGACGCTTGCATTCGCTGCCGCGGCCATTGAAAATATGCAATTAGGGAAGCAGGCCCAGACCGATATTATTAGCATTGGACTGAGCGCTACGGATTACGTGGGACACACCTTCGGCACGGAGGGTACGGAGAGTTGCATCCAAGTGGATCGTTTAGACACGGAGCTTGGTGCATTCTTTGATAAACTGGATAAGGATGGGATTGACTACGTAGTAGTGCTGACTGCAGATCATGGAGGACACGATCTGCCCGAACGTCATCGTATGAATGCCATGCCGATGGAACAGCGCGTAGACATGGCCCTGACACCTAAAGCTCTGAATGCTACCATCGCTGAGAAAGCTGGCCTTCCGGGCAAAAAGGTTATTTGGTCAGATGGACCTTCTGGCGATATTTACTATGATAAGGGCCTTACAGCCGCTCAACGTGCCCGTGTTGAAACCGAGGCGTTAAAATACTTGCGCGCGCATCCCCAAGTACAGACTGTATTCACTAAGGCGGAAATCGCGGCTACCCCTTCTCCGTCGGGACCACCTGAGAGCTGGAGTTTGATCCAGGAAGCTCGCGCGTCATTTTACCCGTCGCGCTCCGGGGACCTGTTACTTTTATTGAAACCTCGTGTGATGAGCATTCCTGAGCAAGCAGTCATGGGCTCGGTTGCAACCCATGGATCTCCATGGGATACGGATCGCCGTGTGCCTATCCTGTTTTGGCGCAAAGGTATGCAGCATTTCGAACAACCCTTAGGAGTAGAGACTGTTGATATTTTGCCCTCCTTGGCTGCACTTATTAAGCTTCCTGTTCCTAAGGATCAGATCGACGGCCGCTGTCTGGACTTGGTCGCCGGCAAGGATGATTCCTGTGCTGGACAG'\n",
        "downstream_nt = 'GGAGGAGGGTCTGGGGGAGGAGGCAGTGGCATGGTGAGCAAGGGCGAGGAGCTGTTCACCGGGGTGGTGCCCATCCTGGTCGAGCTGGACGGCGACGTAAACGGCCACAAGTTCAGCGTGTCCGGCGAGGGCGAGGGCGATGCCACCTACGGCAAGCTGACCCTGAAGTTCATCTGCACCACCGGCAAGCTGCCCGTGCCCTGGCCCACC'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdez7ucQpGfb"
      },
      "source": [
        "#Per-Paramter Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzYko3K52ZPR"
      },
      "source": [
        "##Creating Graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1juYXyJqiRq"
      },
      "source": [
        "##Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ds5r130JpH5R"
      },
      "outputs": [],
      "source": [
        "all_data = []\n",
        "primer_lmin, primer_lmax = 18, 30 # PARAM: primer lengths (inclusive)\n",
        "pcr = p3.thermoanalysis.ThermoAnalysis(dna_conc= 250,\n",
        "                                       mv_conc= 50,\n",
        "                                       dv_conc= 0,\n",
        "                                       dntp_conc= 0,\n",
        "                                       tm_method= 'santalucia',\n",
        "                                       salt_correction_method= 'owczarzy',\n",
        "                                       temp_c= 25)\n",
        "overlap_lmin,overlap_lmax = 45,50\n",
        "oligo_lmin,oligo_lmax = 195,205\n",
        "num_proteins = 3\n",
        "allowed_overlap = 6\n",
        "\n",
        "# user can choose to apply primer cost threshold on gc content and tm\n",
        "apply_threshold= True # apply threshold flag. If true, threshold will be applied\n",
        "min_gc=40\n",
        "max_gc=60\n",
        "min_tm=58\n",
        "max_tm=65\n",
        "max_difference=3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDsUII2TqmbD"
      },
      "source": [
        "##Code To Run"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_length in range(220,1620):\n",
        "\n",
        "  mutreg_nt=mutreg_nt_full[:seq_length]\n",
        "  sequence_nt = upstream_nt + mutreg_nt + downstream_nt\n",
        "  mutreg_l = len(mutreg_nt)\n",
        "  mutreg_start = len(upstream_nt)\n",
        "  mutreg_stop = mutreg_start + mutreg_l\n",
        "  mutreg_aa = translate(mutreg_nt)\n",
        "\n",
        "  nt_range = (-len(upstream_nt), len(mutreg_nt) + len(downstream_nt)+1) #range of nucleotides\n",
        "  l_range = (allowed_overlap+1, primer_lmax+1)\n",
        "\n",
        "  mut_df = create_mut_df()\n",
        "  primer_f, primer_df = create_primer_df()\n",
        "\n",
        "  #Creating the Graph\n",
        "  start_time = time.time()\n",
        "  tracemalloc.start()\n",
        "  G = nx.DiGraph()\n",
        "  primers_init = [Primer(p.start,p.stop) for _,p in primer_f.query('stop<=0').iterrows() if check_threshold(p.tm,p.gc)]  ## all forward primers that end before mutreg and pass threshold\n",
        "  for primer in primers_init:\n",
        "    G.add_edge('s',primer.tup(), weight=primer.w) #intializing the s-primer connection\n",
        "    dfs(primer) #create the rest of the graph\n",
        "\n",
        "  graph_time = int(time.time() - start_time)\n",
        "  graph_memory = tracemalloc.get_traced_memory()[1] / 10**6 #MB\n",
        "  tracemalloc.stop()\n",
        "\n",
        "  #Greedy Solution\n",
        "  start_time = time.time()\n",
        "  greedy_solution, greedy_obj = run_greedy(G, primer_f, primer_df)\n",
        "  greedy_time = time.time() - start_time\n",
        "\n",
        "  #Convert to ILP & Solve\n",
        "  tracemalloc.start()\n",
        "  start_time = time.time()\n",
        "\n",
        "  numVars, numConstrs, setup_time, setup_memory, ILP_time, ILP_memory, actual_values, objective = get_info([G, G])\n",
        "  #numVars, numConstrs, setup_time, setup_memory, ILP_time, ILP_memory = 0,0,0,0,0,0\n",
        "  all_data.append({\"seq length:\": seq_length,\n",
        "                    \"Nodes\":len(G.nodes),\n",
        "                    \"Edges\": len(G.edges),\n",
        "                    \"Time (Graph)\": graph_time,\n",
        "                    \"MP (Graph)\": graph_memory,\n",
        "                    \"Vars\": numVars,\n",
        "                    \"Constr\": numConstrs,\n",
        "                    \"Time (Setup)\": setup_time,\n",
        "                    \"MP (Setup)\": setup_memory,\n",
        "                    \"Time (ILP)\": ILP_time,\n",
        "                    \"MP (ILP)\": ILP_memory,\n",
        "                    \"ILP Solution\": actual_values,\n",
        "                    \"ILP Objective\": objective,\n",
        "                    \"Greedy Solution\": greedy_solution,\n",
        "                    \"Greedy Objective\": greedy_obj,\n",
        "                    \"Greedy Time\": greedy_time})\n",
        "  print(all_data[-1])\n",
        "  break"
      ],
      "metadata": {
        "id": "SzokpLDXX59g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming all_data is a list of dictionaries\n",
        "df = pd.DataFrame(all_data)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "df.to_csv('data.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "lrNTrVAMCXfX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3-cQNE8To4yW",
        "MFTaJFH_qB2p",
        "WXfAgj6lqJQn",
        "3Ah8DwG1FeE6",
        "UzIt-1aCqUAH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
